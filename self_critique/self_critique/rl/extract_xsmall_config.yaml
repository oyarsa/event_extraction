num_epochs: 1
eval_batches: 100

train_file: ../data/genqa_joint/train.json
eval_file: ../data/genqa_joint/dev.json
max_train_samples: null
max_eval_samples: null

reward_model: ../evaluation/output/classifier/fcr-deberta-v3-xsmall-combined/
reward_type: valid
max_reward_seq_length: 400

extraction_model: output/extraction/t5-base
max_generation_length: 128

output_dir: output/rl
run_name: xsmall-t5-base
log_with: null

# Batch sizes need to be lower for models larger than T5-Base
reward_batch_size: 96
ppo_batch_size: 96
ppo_minibatch_size: 96

kl_penalty: kl
adaptive_kl_ctrl: true
init_kl_coef: 0.2

# Greedy decoding
generation_top_k: null
generation_top_p: null
degeneration_penalty: null
generation_do_sample: false
generation_num_beams: 1
